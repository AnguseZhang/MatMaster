import asyncio
import json
import logging
import os
import re
import time
import uuid
from typing import Any, Dict, List

from bohrium import Bohrium
from dotenv import find_dotenv, load_dotenv
from google.adk import Runner
from google.adk.agents import RunConfig
from google.adk.agents.run_config import StreamingMode
from google.adk.artifacts import InMemoryArtifactService
from google.adk.sessions import InMemorySessionService
from google.genai import types

from agents.matmaster_agent.agent import root_agent
from .human_simulator import ConversationGoal, HumanSimulator
from ..utils import load_dataset_json

logger = logging.getLogger(__name__)

load_dotenv(find_dotenv(), override=True)
print(os.getenv('BOHRIUM_API_URL'))


def _validate_l1_tool_calls(
    actual_tools: List[Dict[str, str]],
    expected_tools: List[str],
) -> Dict[str, Any]:
    """
    L1 éªŒè¯ï¼šæ£€æŸ¥å®é™…å·¥å…·è°ƒç”¨æ˜¯å¦ç¬¦åˆé¢„æœŸ
    
    :param actual_tools: å®é™…è°ƒç”¨çš„å·¥å…·åˆ—è¡¨ [{'tool_name': ..., 'description': ...}]
    :param expected_tools: é¢„æœŸçš„å·¥å…·åç§°åˆ—è¡¨ ['tool1', 'tool2']
    :return: éªŒè¯ç»“æœ {'passed': bool, 'reason': str, 'details': dict}
    """
    actual_tool_names = [t['tool_name'] for t in actual_tools]
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šé¢„æœŸå·¥å…·ï¼Œåªæ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    if not expected_tools:
        if actual_tool_names:
            return {
                'passed': True,
                'reason': 'æœªæŒ‡å®šé¢„æœŸå·¥å…·ï¼Œä½†æœ‰å·¥å…·è°ƒç”¨ç”Ÿæˆ',
                'details': {
                    'actual_tools': actual_tool_names,
                    'expected_tools': [],
                }
            }
        else:
            return {
                'passed': False,
                'reason': 'æœªç”Ÿæˆä»»ä½•å·¥å…·è°ƒç”¨',
                'details': {
                    'actual_tools': [],
                    'expected_tools': [],
                }
            }
    
    # æ£€æŸ¥é¢„æœŸå·¥å…·æ˜¯å¦éƒ½è¢«è°ƒç”¨
    missing_tools = [t for t in expected_tools if t not in actual_tool_names]
    extra_tools = [t for t in actual_tool_names if t not in expected_tools]
    
    if missing_tools:
        return {
            'passed': False,
            'reason': f'ç¼ºå°‘é¢„æœŸå·¥å…·è°ƒç”¨: {missing_tools}',
            'details': {
                'actual_tools': actual_tool_names,
                'expected_tools': expected_tools,
                'missing_tools': missing_tools,
                'extra_tools': extra_tools,
            }
        }
    
    return {
        'passed': True,
        'reason': 'æ‰€æœ‰é¢„æœŸå·¥å…·å‡å·²è°ƒç”¨',
        'details': {
            'actual_tools': actual_tool_names,
            'expected_tools': expected_tools,
            'extra_tools': extra_tools,
        }
    }


def _validate_l1b_tool_calls(
    actual_tools: List[Dict[str, Any]],
    expected_tools: List[str],
    expected_args: Dict[str, Any],
) -> Dict[str, Any]:
    """
    L1b éªŒè¯ï¼šæ£€æŸ¥å®é™…å·¥å…·è°ƒç”¨å’Œå‚æ•°æ˜¯å¦ç¬¦åˆé¢„æœŸ
    
    :param actual_tools: å®é™…è°ƒç”¨çš„å·¥å…·åˆ—è¡¨ [{'tool_name': ..., 'tool_args': {...}}]
    :param expected_tools: é¢„æœŸçš„å·¥å…·åç§°åˆ—è¡¨ ['tool1', 'tool2']
    :param expected_args: é¢„æœŸçš„å‚æ•°éªŒè¯è§„åˆ™ {
        'tool_name': {
            'required_keys': ['key1', 'key2'],  # å¿…é¡»åŒ…å«çš„å‚æ•°é”®
            'key_values': {'key1': 'expected_value'},  # å‚æ•°å€¼éªŒè¯ï¼ˆå¯é€‰ï¼‰
            'key_contains': {'key1': 'substring'},  # å‚æ•°å€¼åŒ…å«éªŒè¯ï¼ˆå¯é€‰ï¼‰
            'key_list_contains': {'key1': 'item'},  # æ•°ç»„å‚æ•°åŒ…å«éªŒè¯ï¼ˆå¯é€‰ï¼‰
        }
    }
    :return: éªŒè¯ç»“æœ {'passed': bool, 'reason': str, 'details': dict}
    """
    actual_tool_names = [t['tool_name'] for t in actual_tools]
    
    # é¦–å…ˆæ£€æŸ¥å·¥å…·åç§°
    if expected_tools:
        missing_tools = [t for t in expected_tools if t not in actual_tool_names]
        if missing_tools:
            return {
                'passed': False,
                'reason': f'ç¼ºå°‘é¢„æœŸå·¥å…·è°ƒç”¨: {missing_tools}',
                'details': {
                    'actual_tools': actual_tool_names,
                    'expected_tools': expected_tools,
                    'missing_tools': missing_tools,
                }
            }
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šå‚æ•°éªŒè¯è§„åˆ™ï¼ŒåªéªŒè¯å·¥å…·åç§°
    if not expected_args:
        return {
            'passed': True,
            'reason': 'å·¥å…·åç§°éªŒè¯é€šè¿‡ï¼ŒæœªæŒ‡å®šå‚æ•°éªŒè¯è§„åˆ™',
            'details': {
                'actual_tools': actual_tool_names,
                'expected_tools': expected_tools,
            }
        }
    
    # éªŒè¯å‚æ•°
    args_validation_errors = []
    for tool in actual_tools:
        tool_name = tool.get('tool_name', '')
        tool_args = tool.get('tool_args', {})
        
        if tool_name not in expected_args:
            continue  # è¯¥å·¥å…·æ²¡æœ‰å‚æ•°éªŒè¯è§„åˆ™
        
        rules = expected_args[tool_name]
        
        # æ£€æŸ¥å¿…é¡»åŒ…å«çš„å‚æ•°é”®
        required_keys = rules.get('required_keys', [])
        for key in required_keys:
            if key not in tool_args:
                args_validation_errors.append(
                    f"å·¥å…· {tool_name} ç¼ºå°‘å¿…éœ€å‚æ•°: {key}"
                )
        
        # æ£€æŸ¥å‚æ•°å€¼
        key_values = rules.get('key_values', {})
        for key, expected_value in key_values.items():
            actual_value = tool_args.get(key)
            if actual_value != expected_value:
                args_validation_errors.append(
                    f"å·¥å…· {tool_name} å‚æ•° {key} å€¼ä¸åŒ¹é…: "
                    f"æœŸæœ›={expected_value}, å®é™…={actual_value}"
                )
        
        # æ£€æŸ¥å‚æ•°å€¼åŒ…å«ï¼ˆå­—ç¬¦ä¸²ï¼‰
        key_contains = rules.get('key_contains', {})
        for key, substring in key_contains.items():
            actual_value = str(tool_args.get(key, ''))
            if substring not in actual_value:
                args_validation_errors.append(
                    f"å·¥å…· {tool_name} å‚æ•° {key} ä¸åŒ…å«é¢„æœŸå†…å®¹: "
                    f"æœŸæœ›åŒ…å«={substring}, å®é™…={actual_value}"
                )
        
        # æ£€æŸ¥æ•°ç»„å‚æ•°åŒ…å«
        key_list_contains = rules.get('key_list_contains', {})
        for key, expected_item in key_list_contains.items():
            actual_list = tool_args.get(key, [])
            if not isinstance(actual_list, list):
                actual_list = [actual_list]
            if expected_item not in actual_list:
                args_validation_errors.append(
                    f"å·¥å…· {tool_name} å‚æ•° {key} ä¸åŒ…å«é¢„æœŸå…ƒç´ : "
                    f"æœŸæœ›åŒ…å«={expected_item}, å®é™…={actual_list}"
                )
    
    if args_validation_errors:
        return {
            'passed': False,
            'reason': f'å‚æ•°éªŒè¯å¤±è´¥: {args_validation_errors[0]}',
            'details': {
                'actual_tools': actual_tool_names,
                'expected_tools': expected_tools,
                'validation_errors': args_validation_errors,
            }
        }
    
    return {
        'passed': True,
        'reason': 'å·¥å…·åç§°å’Œå‚æ•°éªŒè¯é€šè¿‡',
        'details': {
            'actual_tools': actual_tool_names,
            'expected_tools': expected_tools,
        }
    }


async def _run_conversation(
    dataset_item: Dict[str, Any],
    max_turn_count: int,
    item_id: int,
    save_mode: str = 'w',
    label_key: str = '',
    truncation_mode: str = '',
) -> Dict[str, Any]:
    """
    æ‰§è¡Œä¸€æ¬¡å¯¹è¯æµ‹è¯•ï¼Œå¹¶è¿”å›ç»“æœ
    :param dataset_item: å•æ¡æµ‹è¯•æ•°æ®
    :param max_turn_count: æœ€å¤§å¯¹è¯è½®æ¬¡
    :param save_mode: å†™æ–‡ä»¶æ¨¡å¼ ("w" è¦†ç›– / "a" è¿½åŠ )
    :param truncation_mode: æˆªæ–­æ¨¡å¼
        - '': ä¸æˆªæ–­ï¼Œå®Œæ•´æ‰§è¡Œ
        - 'L1': åœ¨è®¡åˆ’ç¡®è®¤åæˆªæ–­ï¼ŒåªéªŒè¯å·¥å…·åç§°
        - 'L1b': åœ¨ function_call ç”Ÿæˆåæˆªæ–­ï¼ŒéªŒè¯å·¥å…·åç§°å’Œå‚æ•°
    """
    if item_id is None:
        item_id = 0
    if not os.path.exists(f'logs/job_{item_id}'):
        os.makedirs(f'logs/job_{item_id}')

    session_service = InMemorySessionService()
    artifact_service = InMemoryArtifactService()
    
    # åˆ›å»º sessionï¼Œæ³¨å…¥ truncation_mode
    # L1 æ¨¡å¼ï¼štruncation_mode = True æˆ– 'L1'
    # L1b æ¨¡å¼ï¼štruncation_mode = 'L1b'
    if truncation_mode == 'L1':
        initial_state = {'truncation_mode': True}
    elif truncation_mode == 'L1b':
        initial_state = {'truncation_mode': 'L1b'}
    else:
        initial_state = {}
    
    session = await session_service.create_session(
        app_name='matmaster_agent',
        user_id='human_simulator_test',
        state=initial_state,
    )

    logger.info(f"Test Session: {session.id}")

    runner = Runner(
        app_name='matmaster_agent',
        agent=root_agent,
        session_service=session_service,
        artifact_service=artifact_service,
    )

    simulator = HumanSimulator(max_turn_count=max_turn_count)

    # åœºæ™¯åˆå§‹åŒ–
    scenario = {
        'name': dataset_item['initial_question'],
        'goal': ConversationGoal(
            initial_question=dataset_item['initial_question'],
            expected_outcomes=dataset_item['expected_outcomes'],
            success_criteria=dataset_item['success_criteria'],
        ),
    }

    file_parts = []
    if 'file_urls' in dataset_item:
        for file_url in dataset_item['file_urls']:
            # with open(file_url, "rb") as f:
            #     file_bytes = f.read()
            file_part = types.Part.from_uri(
                file_uri=file_url, mime_type='application/pdf'
            )
            file_parts.append(file_part)

    print(f"\n{'=' * 20} æµ‹è¯•åœºæ™¯: {scenario['name']} {'=' * 20}")

    simulator.set_goal(scenario['goal'])
    initial_question = simulator.get_initial_question()

    print(f"ğŸ¯ å¯¹è¯ç›®æ ‡: {initial_question}")
    print(f"ğŸ“‹ æœŸæœ›ç»“æœ: {', '.join(scenario['goal'].expected_outcomes)}")
    print(f"âœ… æˆåŠŸæ ‡å‡†: {', '.join(scenario['goal'].success_criteria)}")

    # åˆå§‹åŒ–ç»“æœ
    eval_results = {
        'initial_question': initial_question,
        'expected_outcomes': scenario['goal'].expected_outcomes,
        'success_criteria': scenario['goal'].success_criteria,
    }
    for i in range(1, max_turn_count + 1):
        eval_results[f'agent_response_{i}'] = ''
        eval_results[f'user_response_{i}'] = ''

    # å¯¹è¯å¾ªç¯
    turn_count = 0
    while turn_count < max_turn_count:
        if not os.path.exists(f"{label_key}/logs/job_{item_id}"):
            os.makedirs(f"{label_key}/logs/job_{item_id}")
        turn_count += 1
        print(f"\nğŸ”„ ç¬¬ {turn_count} è½®å¯¹è¯:")

        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = (
            initial_question if turn_count == 1 else simulator.get_last_user_response()
        )
        print(f"ğŸ§‘ æ¨¡æ‹Ÿç”¨æˆ·: {user_input}")

        # è°ƒç”¨ agent
        try:
            if turn_count == 1 and file_parts != []:
                content = types.Content(
                    role='user', parts=file_parts + [types.Part(text=user_input)]
                )
            else:
                content = types.Content(
                    role='user', parts=[types.Part(text=user_input)]
                )
            agent_response = ''

            events = runner.run_async(
                user_id=session.user_id,
                session_id=session.id,
                new_message=content,
                run_config=RunConfig(streaming_mode=StreamingMode.SSE),
            )
            
            # ========================== #
            # æ”¶é›†æ‰€æœ‰äº‹ä»¶ä»¥ä¾›æŸ¥çœ‹å’Œåç»­å¤„ç†  #
            # ========================== #
            events_list = []
            l1_truncation_data = None  # L1 æˆªæ–­æ¨¡å¼ä¸‹çš„è®¡åˆ’æ•°æ®
            l1b_truncation_data = None  # L1b æˆªæ–­æ¨¡å¼ä¸‹çš„ function_call æ•°æ®
            
            async for event in events:
                # æ‰“å°æ¯ä¸ªäº‹ä»¶çš„å†…å®¹ï¼Œæ–¹ä¾¿è°ƒè¯•æŸ¥çœ‹
                # print(f"DEBUG: Received event: {event}") 
                
                if event.content and event.content.parts:
                    for part in event.content.parts:
                        if part.text:
                            agent_response += part.text
                        # å¦‚æœä½ æƒ³çœ‹ function_call å†…å®¹ï¼š
                        if part.function_call:
                            print(f"DEBUG: Function Call: {part.function_call}")
                            # æˆªæ–­æ¨¡å¼ï¼šæ•è·æˆªæ–­äº‹ä»¶ï¼ˆæ¥è‡ª function_callï¼‰
                            if truncation_mode:
                                try:
                                    func_name = getattr(part.function_call, 'name', '')
                                    func_args = part.function_call.args
                                    
                                    # L1 æˆªæ–­äº‹ä»¶
                                    if func_name == 'matmaster_l1_truncation':
                                        if isinstance(func_args, dict):
                                            l1_truncation_data = {
                                                'status': func_args.get('status'),
                                                'multi_plans': json.loads(func_args.get('multi_plans', '{}')),
                                                'plan_info': json.loads(func_args.get('plan_info', '{}')),
                                            }
                                            logger.info(f"L1 æˆªæ–­æ•°æ®å·²æ•è·: {l1_truncation_data.get('status')}")
                                    
                                    # L1b æˆªæ–­äº‹ä»¶
                                    elif func_name == 'matmaster_l1b_truncation':
                                        if isinstance(func_args, dict):
                                            l1b_truncation_data = {
                                                'status': func_args.get('status'),
                                                'step_index': func_args.get('step_index'),
                                                'tool_name': func_args.get('tool_name'),
                                                'function_calls': json.loads(func_args.get('function_calls', '[]')),
                                                'plan': json.loads(func_args.get('plan', '{}')),
                                            }
                                            logger.info(f"L1b æˆªæ–­æ•°æ®å·²æ•è·: tool={l1b_truncation_data.get('tool_name')}")
                                            
                                except Exception as e:
                                    logger.warning(f"è§£ææˆªæ–­æ•°æ®å¤±è´¥: {e}")
                            
                # å°†äº‹ä»¶è½¬æ¢ä¸ºå­—å…¸å¹¶ä¿å­˜
                events_list.append(dict(event))

            # å°†äº‹ä»¶ä¿å­˜åˆ°txtæ–‡ä»¶
            with open(
                f"{label_key}/logs/job_{item_id}/turn_{turn_count}.txt",
                'w',
                encoding='utf-8',
            ) as f:
                f.write(str(events_list))

        except asyncio.CancelledError:
            msg = 'ä»»åŠ¡è¢«å–æ¶ˆï¼Œå¯èƒ½æ˜¯è¶…æ—¶æˆ–ä½œç”¨åŸŸå–æ¶ˆå¯¼è‡´'
            logger.error(msg)
            eval_results[f'agent_response_{turn_count}'] = msg
            raise
        except Exception as e:
            logger.error(f"è·å–agentå“åº”å¤±è´¥: {e}")
            eval_results[f'agent_response_{turn_count}'] = str(e)
            raise e

        eval_results[f'agent_response_{turn_count}'] = agent_response
        print(f"ğŸ¤– ADK Agent: {agent_response}")

        # ===== L1 æˆªæ–­æ¨¡å¼ï¼šæå‰é€€å‡ºå¹¶éªŒè¯ =====
        if truncation_mode == 'L1' and l1_truncation_data:
            print('\nğŸ“‹ L1 æˆªæ–­æ¨¡å¼ - è®¡åˆ’ç”Ÿæˆå®Œæˆï¼Œè·³è¿‡æ‰§è¡Œé˜¶æ®µ')
            
            # æå–å®é™…è°ƒç”¨çš„å·¥å…·åˆ—è¡¨
            actual_tools = []
            multi_plans = l1_truncation_data.get('multi_plans', {})
            if multi_plans and 'plans' in multi_plans:
                for plan in multi_plans['plans']:
                    for step in plan.get('steps', []):
                        if step.get('tool_name'):
                            actual_tools.append({
                                'tool_name': step['tool_name'],
                                'description': step.get('description', ''),
                            })
            
            # L1 éªŒè¯ï¼šæ£€æŸ¥å·¥å…·è°ƒç”¨æ˜¯å¦ç¬¦åˆé¢„æœŸ
            expected_tools = dataset_item.get('expected_tools', [])
            l1_validation_result = _validate_l1_tool_calls(actual_tools, expected_tools)
            
            eval_results.update({
                'truncation_mode': 'L1',
                'l1_truncation_data': l1_truncation_data,
                'actual_tools': actual_tools,
                'expected_tools': expected_tools,
                'l1_validation': l1_validation_result,
                'total_turns': turn_count,
                'final_state': 'l1_truncated',
            })
            
            print(f"   - å®é™…å·¥å…·è°ƒç”¨: {[t['tool_name'] for t in actual_tools]}")
            print(f"   - é¢„æœŸå·¥å…·è°ƒç”¨: {expected_tools}")
            print(f"   - L1 éªŒè¯ç»“æœ: {'é€šè¿‡' if l1_validation_result['passed'] else 'å¤±è´¥'}")
            if not l1_validation_result['passed']:
                print(f"   - å¤±è´¥åŸå› : {l1_validation_result.get('reason', 'N/A')}")
            
            # ä¿å­˜ç»“æœå¹¶é€€å‡º
            with open('evaluation_results.json', save_mode, encoding='utf-8') as f:
                json.dump(eval_results, f, indent=4, ensure_ascii=False)
            
            await runner.close()
            return eval_results
        # ===== L1 æˆªæ–­æ¨¡å¼ç»“æŸ =====

        # ===== L1b æˆªæ–­æ¨¡å¼ï¼šéªŒè¯å·¥å…·åç§°å’Œå‚æ•° =====
        if truncation_mode == 'L1b' and l1b_truncation_data:
            print('\nğŸ“‹ L1b æˆªæ–­æ¨¡å¼ - function_call å·²æ•è·ï¼ŒéªŒè¯å·¥å…·å‚æ•°')
            
            # æå–å®é™…è°ƒç”¨çš„å·¥å…·å’Œå‚æ•°
            function_calls = l1b_truncation_data.get('function_calls', [])
            actual_tools = []
            actual_args = []
            for fc in function_calls:
                actual_tools.append({
                    'tool_name': fc.get('tool_name', ''),
                    'tool_args': fc.get('tool_args', {}),
                })
                actual_args.append(fc.get('tool_args', {}))
            
            # L1b éªŒè¯ï¼šæ£€æŸ¥å·¥å…·åç§°å’Œå‚æ•°
            expected_tools = dataset_item.get('expected_tools', [])
            expected_args = dataset_item.get('expected_args', {})
            l1b_validation_result = _validate_l1b_tool_calls(
                actual_tools, expected_tools, expected_args
            )
            
            eval_results.update({
                'truncation_mode': 'L1b',
                'l1b_truncation_data': l1b_truncation_data,
                'actual_tools': actual_tools,
                'actual_args': actual_args,
                'expected_tools': expected_tools,
                'expected_args': expected_args,
                'l1b_validation': l1b_validation_result,
                'total_turns': turn_count,
                'final_state': 'l1b_truncated',
            })
            
            print(f"   - å®é™…å·¥å…·è°ƒç”¨: {[t['tool_name'] for t in actual_tools]}")
            print(f"   - å®é™…å‚æ•°: {actual_args}")
            print(f"   - é¢„æœŸå·¥å…·è°ƒç”¨: {expected_tools}")
            print(f"   - é¢„æœŸå‚æ•°: {expected_args}")
            print(f"   - L1b éªŒè¯ç»“æœ: {'é€šè¿‡' if l1b_validation_result['passed'] else 'å¤±è´¥'}")
            if not l1b_validation_result['passed']:
                print(f"   - å¤±è´¥åŸå› : {l1b_validation_result.get('reason', 'N/A')}")
            
            # ä¿å­˜ç»“æœå¹¶é€€å‡º
            with open('evaluation_results.json', save_mode, encoding='utf-8') as f:
                json.dump(eval_results, f, indent=4, ensure_ascii=False)
            
            await runner.close()
            return eval_results
        # ===== L1b æˆªæ–­æ¨¡å¼ç»“æŸ =====

        # æå– job_id
        job_jsons = re.findall(
            r'<bohrium-chat-msg>(.*?)</bohrium-chat-msg>', agent_response
        )
        job_ids: List[str] = []
        for job_json in job_jsons:
            try:
                job_json = json.loads(job_json)
                if 'eventData' in job_json and 'content' in job_json['eventData']:
                    content = job_json['eventData']['content']
                    if 'job_list' in content and 'job_id' in content['job_list']:
                        job_ids.append(content['job_list']['job_id'])
            except Exception as e:
                logger.error(f"æå–job_idå¤±è´¥: {e}")

        # æŸ¥è¯¢ job çŠ¶æ€
        if job_ids:
            job_ids = list(set(job_ids))
            while True:
                time.sleep(10)
                all_finished = True
                for job_id in job_ids:
                    try:
                        bohrium_client = Bohrium(
                            base_url=os.getenv(
                                'BOHRIUM_API_URL',
                                'https://test.openapi.bohrium.dp.tech',
                            ),
                            access_key=os.getenv('MATERIALS_ACCESS_KEY'),
                            project_id=os.getenv('MATERIALS_PROJECT_ID'),
                        )
                        job_info = bohrium_client.job.detail(job_id)
                    except Exception as e:
                        import traceback

                        print(f"tracebackkkkkkkkkk, {traceback.print_exc()}")
                        logger.error(f"æŸ¥è¯¢jobçŠ¶æ€å¤±è´¥: {e}")
                        all_finished = False
                        continue

                    logger.info(f"æŸ¥è¯¢åˆ°jobçŠ¶æ€: {job_id} - çŠ¶æ€: {job_info['status']}")
                    if job_info['status'] not in [-1, 2]:
                        all_finished = False
                if all_finished:
                    break

            user_response, should_continue = simulator.get_bohr_results(
                agent_response, job_ids
            )
        else:
            user_response, should_continue = simulator.generate_response(agent_response)

        eval_results[f'user_response_{turn_count}'] = user_response
        print(f"ğŸ§‘ æ¨¡æ‹Ÿç”¨æˆ·: {user_response}")

        if not should_continue:
            print(f"âœ… å¯¹è¯åœ¨ç¬¬{turn_count}è½®ç»“æŸ")
            break

    # å¯¹è¯æ€»ç»“
    summary = simulator.get_conversation_summary()
    eval_results.update(
        {
            'total_turns': summary['total_turns'],
            'final_state': summary['final_state'],
            'duration_minutes': summary['duration_minutes'],
        }
    )

    print('\nğŸ“Š å¯¹è¯æ‘˜è¦:')
    print(f"   - æ€»è½®æ¬¡: {summary['total_turns']}")
    print(f"   - æœ€ç»ˆçŠ¶æ€: {summary['final_state']}")
    print(f"   - è€—æ—¶: {summary['duration_minutes']:.1f} åˆ†é’Ÿ")

    # ä¿å­˜ç»“æœ
    with open('evaluation_results.json', save_mode, encoding='utf-8') as f:
        json.dump(eval_results, f, indent=4, ensure_ascii=False)

    if summary['final_state'] == 'satisfied':
        print('âœ… æµ‹è¯•é€šè¿‡: å¯¹è¯æˆåŠŸå®Œæˆ')
    else:
        print('âŒ æµ‹è¯•å¤±è´¥: å¯¹è¯æœªæˆåŠŸå®Œæˆ')

    await runner.close()
    return eval_results


async def evaluation_threads_single_task(
    file_path: str,
    item_id: int,
    max_turn_count: int = 10,
    label_key: str = '',
    max_retries: int = 1,
    base_backoff: float = 5.0,
    truncation_mode: str = '',
):
    """
    æµ‹è¯•å•ä¸ªæ•°æ®ï¼ˆå¸¦é‡è¯•ï¼‰
    
    :param truncation_mode: æˆªæ–­æ¨¡å¼
        - '': ä¸æˆªæ–­ï¼Œå®Œæ•´æ‰§è¡Œ
        - 'L1': åœ¨è®¡åˆ’ç¡®è®¤åæˆªæ–­ï¼ŒåªéªŒè¯å·¥å…·åç§°
        - 'L1b': åœ¨ function_call ç”Ÿæˆåæˆªæ–­ï¼ŒéªŒè¯å·¥å…·åç§°å’Œå‚æ•°
    """
    print('=' * 80)
    if truncation_mode == 'L1':
        print('ğŸ”¬ L1 æˆªæ–­æ¨¡å¼ - ä»…éªŒè¯å·¥å…·åç§°')
    elif truncation_mode == 'L1b':
        print('ğŸ”¬ L1b æˆªæ–­æ¨¡å¼ - éªŒè¯å·¥å…·åç§°å’Œå‚æ•°')
    else:
        print('ğŸ¤– ä¸ADK Agentå¤šè½®å¯¹è¯æµ‹è¯•')
    print('=' * 80)

    dataset_json = json.loads(load_dataset_json(file_path))
    dataset_item = dataset_json[item_id]
    
    # æˆªæ–­æ¨¡å¼ä¸‹å‡å°‘ç­‰å¾…æ—¶é—´
    if not truncation_mode:
        time.sleep(10)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹

    attempt = 0
    while attempt < max_retries:
        try:
            result = await _run_conversation(
                dataset_item,
                max_turn_count,
                save_mode='a',
                item_id=item_id,
                label_key=label_key,
                truncation_mode=truncation_mode,
            )
            # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
            break
        except asyncio.CancelledError:
            # å–æ¶ˆåº”ç›´æ¥ä¼ æ’­
            logger.error('ä»»åŠ¡è¢«å–æ¶ˆï¼Œåœæ­¢é‡è¯•')
            raise
        except Exception as e:
            attempt += 1
            logger.error(f"ç¬¬ {attempt} æ¬¡æ‰§è¡Œå¤±è´¥: {e}")
            if attempt >= max_retries:
                logger.error('å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ŒæŠ›å‡ºå¼‚å¸¸')
                raise
            backoff = base_backoff * (2 ** (attempt - 1))
            print(f"âš ï¸ ç¬¬ {attempt} æ¬¡æ‰§è¡Œå¤±è´¥ï¼Œ{backoff} ç§’åé‡è¯•...")
            await asyncio.sleep(backoff)

    print('\n' + '=' * 80)
    if truncation_mode:
        print(f'ğŸ‰ {truncation_mode} æˆªæ–­æµ‹è¯•å®Œæˆï¼')
    else:
        print('ğŸ‰ å•æ¡å¤šè½®å¯¹è¯æµ‹è¯•å®Œæˆï¼')
    print('=' * 80)

    return result